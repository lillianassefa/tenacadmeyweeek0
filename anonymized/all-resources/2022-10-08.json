[
  {
    "client_msg_id": "d6ef74a8-9f64-4356-a342-9727c283f5d7",
    "type": "message",
    "text": "<https://www.youtube.com/watch?v=kWGu_npzpsI&amp;ab_channel=AnalyticsExcellence>",
    "user": "U03V61VGQG0",
    "ts": "1665220493.953919",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "ONCO",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.youtube.com/watch?v=kWGu_npzpsI&ab_channel=AnalyticsExcellence"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "5e18062f5298",
      "image_72": "https://avatars.slack-edge.com/2022-08-29/3997574519670_5e18062f5298c6182ca5_72.jpg",
      "first_name": "Paula",
      "real_name": "Paula Bryant",
      "display_name": "Paula Bryant",
      "team": "T03U4J8HMUG",
      "name": "Paula",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.youtube.com/watch?v=kWGu_npzpsI&amp;ab_channel=AnalyticsExcellence",
        "thumb_url": "https://i.ytimg.com/vi/kWGu_npzpsI/hqdefault.jpg",
        "thumb_width": 480,
        "thumb_height": 360,
        "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/kWGu_npzpsI?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"24. Pyspark Streaming: Streaming with Apache Kafka\"></iframe>",
        "video_html_width": 400,
        "video_html_height": 225,
        "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
        "id": 1,
        "original_url": "https://www.youtube.com/watch?v=kWGu_npzpsI&amp;ab_channel=AnalyticsExcellence",
        "fallback": "YouTube Video: 24. Pyspark Streaming: Streaming with Apache Kafka",
        "title": "24. Pyspark Streaming: Streaming with Apache Kafka",
        "title_link": "https://www.youtube.com/watch?v=kWGu_npzpsI&amp;ab_channel=AnalyticsExcellence",
        "author_name": "Analytics Excellence",
        "author_link": "https://www.youtube.com/c/AnalyticsExcellence",
        "service_name": "YouTube",
        "service_url": "https://www.youtube.com/"
      }
    ]
  },
  {
    "client_msg_id": "89a2cf0f-4a0a-422d-86f3-59f6803aa44b",
    "type": "message",
    "text": "<https://timsainburg.com/noise-reduction-python.html>",
    "user": "U03V61VGQG0",
    "ts": "1665220511.507029",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "=za",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://timsainburg.com/noise-reduction-python.html"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "5e18062f5298",
      "image_72": "https://avatars.slack-edge.com/2022-08-29/3997574519670_5e18062f5298c6182ca5_72.jpg",
      "first_name": "Paula",
      "real_name": "Paula Bryant",
      "display_name": "Paula Bryant",
      "team": "T03U4J8HMUG",
      "name": "Paula",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://timsainburg.com/noise-reduction-python.html",
        "ts": 1530982860,
        "service_icon": "https://timsainburg.com/theme/img/starling-small.ico",
        "id": 1,
        "original_url": "https://timsainburg.com/noise-reduction-python.html",
        "fallback": "Tim Sainburg: Noise reduction using spectral gating in python",
        "text": "A quick implementation of a noise reduction algorithm using spectral gating in python.",
        "title": "Noise reduction using spectral gating in python",
        "title_link": "https://timsainburg.com/noise-reduction-python.html",
        "service_name": "Tim Sainburg"
      }
    ]
  },
  {
    "client_msg_id": "64b72d4e-8de7-4469-95c0-ea786613df02",
    "type": "message",
    "text": "<https://www.kaggle.com/code/robikscube/working-with-audio-in-python/notebook>",
    "user": "U03V61VGQG0",
    "ts": "1665220525.857649",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "+HXwX",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.kaggle.com/code/robikscube/working-with-audio-in-python/notebook"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "5e18062f5298",
      "image_72": "https://avatars.slack-edge.com/2022-08-29/3997574519670_5e18062f5298c6182ca5_72.jpg",
      "first_name": "Paula",
      "real_name": "Paula Bryant",
      "display_name": "Paula Bryant",
      "team": "T03U4J8HMUG",
      "name": "Paula",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.kaggle.com/code/robikscube/working-with-audio-in-python/notebook",
        "thumb_url": "https://storage.googleapis.com/kaggle-avatars/thumbnails/644036-kg.jpeg",
        "thumb_width": 100,
        "thumb_height": 100,
        "service_icon": "https://www.kaggle.com/favicon.ico",
        "id": 1,
        "original_url": "https://www.kaggle.com/code/robikscube/working-with-audio-in-python/notebook",
        "fallback": ":loud_sound: Working with Audio in Python",
        "text": "Explore and run machine learning code with Kaggle Notebooks | Using data from RAVDESS Emotional speech audio",
        "title": ":loud_sound: Working with Audio in Python",
        "title_link": "https://www.kaggle.com/code/robikscube/working-with-audio-in-python/notebook",
        "service_name": "kaggle.com"
      }
    ]
  },
  {
    "client_msg_id": "38108e39-e91d-4386-8805-f6547fcf2d92",
    "type": "message",
    "text": "<https://itsfoss.com/set-java-home-ubuntu/>",
    "user": "U03UJH1EQQL",
    "ts": "1665228827.992089",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "cxiG",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://itsfoss.com/set-java-home-ubuntu/"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "81b299d9869c",
      "image_72": "https://avatars.slack-edge.com/2022-08-20/3953555815671_81b299d9869ca44e70c1_72.png",
      "first_name": "Kelly",
      "real_name": "Kelly Soto",
      "display_name": "Kelly Soto",
      "team": "T03U4J8HMUG",
      "name": "Kelly",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://itsfoss.com/set-java-home-ubuntu/",
        "image_url": "https://itsfoss.com/wp-content/uploads/2021/09/set-java-home-ubuntu.png",
        "image_width": 444,
        "image_height": 250,
        "image_bytes": 32937,
        "service_icon": "https://itsfoss.com/wp-content/uploads/2017/06/cropped-Logo-redsigned-without-name-180x180.png",
        "id": 1,
        "original_url": "https://itsfoss.com/set-java-home-ubuntu/",
        "fallback": "It's FOSS: How to Set JAVA_HOME in Ubuntu Linux Correctly",
        "text": "Your Linux system is complain that \"java_home environment variable is not set\"? Learn and understand how to set java home path in Ubuntu Linux correctly.",
        "title": "How to Set JAVA_HOME in Ubuntu Linux Correctly",
        "title_link": "https://itsfoss.com/set-java-home-ubuntu/",
        "service_name": "It's FOSS"
      }
    ]
  },
  {
    "client_msg_id": "3af5f0c2-6b68-477e-bf10-3e4fd31c54ab",
    "type": "message",
    "text": "<https://medium.com/swlh/using-airflow-to-schedule-spark-jobs-811becf3a960>",
    "user": "U03UD5B7C3X",
    "ts": "1665229376.367719",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "KIue",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://medium.com/swlh/using-airflow-to-schedule-spark-jobs-811becf3a960"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "gb4893f68d1b",
      "image_72": "https://secure.gravatar.com/avatar/b4893f68d1b3098aa61b283721cedfbb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
      "first_name": "Elizabeth",
      "real_name": "Elizabeth Hall",
      "display_name": "Elizabeth Hall",
      "team": "T03U4J8HMUG",
      "name": "Elizabeth",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://medium.com/swlh/using-airflow-to-schedule-spark-jobs-811becf3a960",
        "ts": 1606590288,
        "image_url": "https://miro.medium.com/max/1072/1*TzRyGCOSa4aZhda3B2H-qg.png",
        "image_width": 751,
        "image_height": 250,
        "image_bytes": 47825,
        "service_icon": "https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png",
        "id": 1,
        "original_url": "https://medium.com/swlh/using-airflow-to-schedule-spark-jobs-811becf3a960",
        "fallback": "Medium: Using Airflow to Schedule Spark Jobs",
        "text": "Apache Airflow is used for defining and managing a Directed Acyclic Graph of tasks. Data guys programmatically orchestrate and schedule\u2026",
        "title": "Using Airflow to Schedule Spark Jobs",
        "title_link": "https://medium.com/swlh/using-airflow-to-schedule-spark-jobs-811becf3a960",
        "service_name": "Medium",
        "fields": [
          {
            "value": "8 min read",
            "title": "Reading time",
            "short": true
          }
        ]
      }
    ]
  },
  {
    "client_msg_id": "66cbd28d-7675-4adf-911c-de0014cc4f22",
    "type": "message",
    "text": "<https://www.youtube.com/watch?v=ofPDOmMKRis>\n\n(it's in hindi i think, but the logic works)",
    "user": "U03UD5B7C3X",
    "ts": "1665229451.218989",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "/8v",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.youtube.com/watch?v=ofPDOmMKRis"
              },
              {
                "type": "text",
                "text": "\n\n(it's in hindi i think, but the logic works)"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "gb4893f68d1b",
      "image_72": "https://secure.gravatar.com/avatar/b4893f68d1b3098aa61b283721cedfbb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
      "first_name": "Elizabeth",
      "real_name": "Elizabeth Hall",
      "display_name": "Elizabeth Hall",
      "team": "T03U4J8HMUG",
      "name": "Elizabeth",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.youtube.com/watch?v=ofPDOmMKRis",
        "thumb_url": "https://i.ytimg.com/vi/ofPDOmMKRis/hqdefault.jpg",
        "thumb_width": 480,
        "thumb_height": 360,
        "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/ofPDOmMKRis?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Run PySpark Job using Airflow | Apache Airflow Practical Tutorial |Part 4|Data Making|DM| DataMaking\"></iframe>",
        "video_html_width": 400,
        "video_html_height": 225,
        "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
        "id": 1,
        "original_url": "https://www.youtube.com/watch?v=ofPDOmMKRis",
        "fallback": "YouTube Video: Run PySpark Job using Airflow | Apache Airflow Practical Tutorial |Part 4|Data Making|DM| DataMaking",
        "title": "Run PySpark Job using Airflow | Apache Airflow Practical Tutorial |Part 4|Data Making|DM| DataMaking",
        "title_link": "https://www.youtube.com/watch?v=ofPDOmMKRis",
        "author_name": "DataMaking",
        "author_link": "https://www.youtube.com/c/DataMaking",
        "service_name": "YouTube",
        "service_url": "https://www.youtube.com/"
      }
    ]
  },
  {
    "client_msg_id": "12ccebbc-e860-4622-8de2-f58b3e5bacac",
    "type": "message",
    "text": "<https://medium.com/analytics-vidhya/airflow-spark-s3-stitching-it-all-together-1acbfba67e33>",
    "user": "U03UD5B7C3X",
    "ts": "1665229618.345309",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "0Zdmt",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://medium.com/analytics-vidhya/airflow-spark-s3-stitching-it-all-together-1acbfba67e33"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "gb4893f68d1b",
      "image_72": "https://secure.gravatar.com/avatar/b4893f68d1b3098aa61b283721cedfbb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
      "first_name": "Elizabeth",
      "real_name": "Elizabeth Hall",
      "display_name": "Elizabeth Hall",
      "team": "T03U4J8HMUG",
      "name": "Elizabeth",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://medium.com/analytics-vidhya/airflow-spark-s3-stitching-it-all-together-1acbfba67e33",
        "ts": 1619107164,
        "image_url": "https://miro.medium.com/max/852/1*TEfXPKRMwQ5A66W6GAR--Q.png",
        "image_width": 440,
        "image_height": 250,
        "image_bytes": 51708,
        "service_icon": "https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png",
        "id": 1,
        "original_url": "https://medium.com/analytics-vidhya/airflow-spark-s3-stitching-it-all-together-1acbfba67e33",
        "fallback": "Medium: Airflow, Spark &amp; S3, stitching it all together",
        "text": "In my previous post, I described one of the many ways to set up your own Spark cluster (in AWS) and submitting spark jobs in that cluster\u2026",
        "title": "Airflow, Spark &amp; S3, stitching it all together",
        "title_link": "https://medium.com/analytics-vidhya/airflow-spark-s3-stitching-it-all-together-1acbfba67e33",
        "service_name": "Medium",
        "fields": [
          {
            "value": "8 min read",
            "title": "Reading time",
            "short": true
          }
        ]
      }
    ],
    "reactions": [
      {
        "name": "raised_hands",
        "users": [
          "U03U1FNPEUX"
        ],
        "count": 1
      }
    ]
  },
  {
    "client_msg_id": "1b6110e8-af2a-45ed-9369-f6d16777f762",
    "type": "message",
    "text": "<https://www.npmjs.com/package/audio-react-recorder>",
    "user": "U03U1FNPEUX",
    "ts": "1665237989.776959",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "b1rfN",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.npmjs.com/package/audio-react-recorder"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "37a12a7dbb92",
      "image_72": "https://avatars.slack-edge.com/2022-09-09/4058043481011_37a12a7dbb926b2c9c86_72.png",
      "first_name": "Joshua",
      "real_name": "Joshua Rhodes",
      "display_name": "Joshua Rhodes",
      "team": "T03U4J8HMUG",
      "name": "Joshua",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.npmjs.com/package/audio-react-recorder",
        "thumb_url": "https://static.npmjs.com/338e4905a2684ca96e08c7780fc68412.png",
        "thumb_width": 1200,
        "thumb_height": 630,
        "service_icon": "https://static.npmjs.com/58a19602036db1daee0d7863c94673a4.png",
        "id": 1,
        "original_url": "https://www.npmjs.com/package/audio-react-recorder",
        "fallback": "npm: audio-react-recorder",
        "text": "Audio / Voice Recorder for React. Latest version: 1.0.4, last published: 2 years ago. Start using audio-react-recorder in your project by running `npm i audio-react-recorder`. There are 8 other projects in the npm registry using audio-react-recorder.",
        "title": "audio-react-recorder",
        "title_link": "https://www.npmjs.com/package/audio-react-recorder",
        "service_name": "npm"
      }
    ]
  },
  {
    "client_msg_id": "0d7d3b80-57d0-4b7f-a9b3-6b08ad384197",
    "type": "message",
    "text": "<https://blogit.michelin.io/kafka-to-delta-lake-using-apache-spark-streaming-avro/>",
    "user": "U03UUP56MDF",
    "ts": "1665240293.849369",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "WHO",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://blogit.michelin.io/kafka-to-delta-lake-using-apache-spark-streaming-avro/"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g00725318689",
      "image_72": "https://secure.gravatar.com/avatar/007253186898705d4f28c384188b8a63.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0007-72.png",
      "first_name": "Mark",
      "real_name": "Mark Crawford",
      "display_name": "Mark Crawford",
      "team": "T03U4J8HMUG",
      "name": "Mark",
      "is_restricted": false,
      "is_ultra_restricted": false
    }
  },
  {
    "client_msg_id": "194212c6-4ad2-4898-9534-11c2de7aa911",
    "type": "message",
    "text": "<https://strimzi.io/blog/2021/01/07/consumer-tuning/>",
    "user": "U03UUP56MDF",
    "ts": "1665240336.172339",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "D6+8b",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://strimzi.io/blog/2021/01/07/consumer-tuning/"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g00725318689",
      "image_72": "https://secure.gravatar.com/avatar/007253186898705d4f28c384188b8a63.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0007-72.png",
      "first_name": "Mark",
      "real_name": "Mark Crawford",
      "display_name": "Mark Crawford",
      "team": "T03U4J8HMUG",
      "name": "Mark",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://strimzi.io/blog/2021/01/07/consumer-tuning/",
        "service_icon": "https://strimzi.io/favicon.ico",
        "id": 1,
        "original_url": "https://strimzi.io/blog/2021/01/07/consumer-tuning/",
        "fallback": "Optimizing Kafka consumers",
        "text": "Strimzi provides a way to run an Apache Kafka cluster on Kubernetes in various deployment configurations.",
        "title": "Optimizing Kafka consumers",
        "title_link": "https://strimzi.io/blog/2021/01/07/consumer-tuning/",
        "service_name": "strimzi.io"
      }
    ]
  },
  {
    "client_msg_id": "f82b6e06-f47f-4a28-93f5-e75f69581438",
    "type": "message",
    "text": "Life Savers!!!\n<https://hevodata.com/learn/connect-kafka-to-s3/|https://hevodata.com/learn/connect-kafka-to-s3/>\n<https://levelup.gitconnected.com/build-flask-apis-using-socketio-to-produce-consume-kafka-messages-95a15df2d1bc|https://levelup.gitconnected.com/build-flask-apis-using-socketio-to-produce-consume-kafka-messages-95a15df2d1bc>\n<https://hub.docker.com/r/wurstmeister/kafka/|https://hub.docker.com/r/wurstmeister/kafka/>\n<https://www.digitalocean.com/community/questions/how-to-fix-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket|https://www.digitalocean.com/community/questions/how-to-fix-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket>\n<https://dzone.com/articles/installing-and-configuring-confluent-platform-kafk|https://dzone.com/articles/installing-and-configuring-confluent-platform-kafk>\n<https://docs.aws.amazon.com/cloudhsm/latest/userguide/ki-al2.html|https://docs.aws.amazon.com/cloudhsm/latest/userguide/ki-al2.html>",
    "user": "U03UG0YHAUT",
    "ts": "1665240790.969599",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "fTF",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "text",
                "text": "Life Savers!!!\n"
              },
              {
                "type": "link",
                "url": "https://hevodata.com/learn/connect-kafka-to-s3/",
                "text": "https://hevodata.com/learn/connect-kafka-to-s3/"
              },
              {
                "type": "text",
                "text": "\n"
              },
              {
                "type": "link",
                "url": "https://levelup.gitconnected.com/build-flask-apis-using-socketio-to-produce-consume-kafka-messages-95a15df2d1bc",
                "text": "https://levelup.gitconnected.com/build-flask-apis-using-socketio-to-produce-consume-kafka-messages-95a15df2d1bc"
              },
              {
                "type": "text",
                "text": "\n"
              },
              {
                "type": "link",
                "url": "https://hub.docker.com/r/wurstmeister/kafka/",
                "text": "https://hub.docker.com/r/wurstmeister/kafka/"
              },
              {
                "type": "text",
                "text": "\n"
              },
              {
                "type": "link",
                "url": "https://www.digitalocean.com/community/questions/how-to-fix-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket",
                "text": "https://www.digitalocean.com/community/questions/how-to-fix-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket"
              },
              {
                "type": "text",
                "text": "\n"
              },
              {
                "type": "link",
                "url": "https://dzone.com/articles/installing-and-configuring-confluent-platform-kafk",
                "text": "https://dzone.com/articles/installing-and-configuring-confluent-platform-kafk"
              },
              {
                "type": "text",
                "text": "\n"
              },
              {
                "type": "link",
                "url": "https://docs.aws.amazon.com/cloudhsm/latest/userguide/ki-al2.html",
                "text": "https://docs.aws.amazon.com/cloudhsm/latest/userguide/ki-al2.html"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "e7b0c8269999",
      "image_72": "https://avatars.slack-edge.com/2022-09-20/4099393715542_e7b0c82699998d3b3ade_72.jpg",
      "first_name": "Daniel",
      "real_name": "Daniel Brown",
      "display_name": "Daniel Brown",
      "team": "T03U4J8HMUG",
      "name": "Daniel",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://hevodata.com/learn/connect-kafka-to-s3/",
        "ts": 1604563922,
        "image_url": "https://res.cloudinary.com/hevo/images/f_auto,q_auto/v1604556962/hevo-learn/KTS3/KTS3.png?_i=AA",
        "image_width": 444,
        "image_height": 250,
        "image_bytes": 63773,
        "service_icon": "https://res.cloudinary.com/hevo/images/f_auto,q_auto/v1587655389/logo-8/logo-8.png?_i=AA",
        "id": 1,
        "original_url": "https://hevodata.com/learn/connect-kafka-to-s3/",
        "fallback": "Learn | Hevo: Connect Kafka to S3: 6 Easy Steps",
        "text": "This blog teaches you how to set up a Kafka to S3 integration. It provides a step-by-step guide to help you connect them and analyse your data with ease!",
        "title": "Connect Kafka to S3: 6 Easy Steps",
        "title_link": "https://hevodata.com/learn/connect-kafka-to-s3/",
        "service_name": "Learn | Hevo",
        "fields": [
          {
            "value": "Divij Chawla",
            "title": "Written by",
            "short": true
          },
          {
            "value": "15 minutes",
            "title": "Time to read",
            "short": true
          }
        ]
      },
      {
        "from_url": "https://levelup.gitconnected.com/build-flask-apis-using-socketio-to-produce-consume-kafka-messages-95a15df2d1bc",
        "ts": 1614264528,
        "image_url": "https://miro.medium.com/max/1200/1*Cq2Mu4HPR48VJpmtYeeaXA.png",
        "image_width": 824,
        "image_height": 250,
        "image_bytes": 74781,
        "service_icon": "https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png",
        "id": 2,
        "original_url": "https://levelup.gitconnected.com/build-flask-apis-using-socketio-to-produce-consume-kafka-messages-95a15df2d1bc",
        "fallback": "Medium: Build Flask APIs using SocketIO to Produce/Consume Kafka Messages",
        "text": "Expose your Docker based Kafka clusters via python Flask sockets to produce/consume messages in a HTML page",
        "title": "Build Flask APIs using SocketIO to Produce/Consume Kafka Messages",
        "title_link": "https://levelup.gitconnected.com/build-flask-apis-using-socketio-to-produce-consume-kafka-messages-95a15df2d1bc",
        "service_name": "Medium",
        "fields": [
          {
            "value": "5 min read",
            "title": "Reading time",
            "short": true
          }
        ]
      },
      {
        "from_url": "https://www.digitalocean.com/community/questions/how-to-fix-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket",
        "thumb_url": "https://www.digitalocean.com/_next/static/media/social-share-default.e8530e9e.jpeg",
        "thumb_width": 1200,
        "thumb_height": 600,
        "service_icon": "https://www.digitalocean.com/_next/static/media/apple-touch-icon.d7edaa01.png",
        "id": 3,
        "original_url": "https://www.digitalocean.com/community/questions/how-to-fix-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket",
        "fallback": "How to fix docker: Got permission denied while trying to connect to the Docker daemon socket  | DigitalOcean",
        "text": "I\u2019ve just installed docker but I have to run it with sudo every time. If I don\u2019t add sudo I get the following error: Got permission denied while trying ...",
        "title": "How to fix docker: Got permission denied while trying to connect to the Docker daemon socket  | DigitalOcean",
        "title_link": "https://www.digitalocean.com/community/questions/how-to-fix-docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket",
        "service_name": "digitalocean.com"
      },
      {
        "from_url": "https://dzone.com/articles/installing-and-configuring-confluent-platform-kafk",
        "image_url": "https://dz2cdn4.dzone.com/storage/article-thumb/13503719-thumb.jpg",
        "image_width": 400,
        "image_height": 250,
        "image_bytes": 100213,
        "service_icon": "https://dz2cdn1.dzone.com/themes/dz20/images/favicon.png",
        "id": 4,
        "original_url": "https://dzone.com/articles/installing-and-configuring-confluent-platform-kafk",
        "fallback": "dzone.com: Install and Configure Confluent Platform (Kafka) in AWS EC2 Instance RHEL 8 - DZone Cloud",
        "text": "In this article, I'm gonna show you how to install and configure a self-manage Confluent Platform in the AWS EC2 instance.",
        "title": "Install and Configure Confluent Platform (Kafka) in AWS EC2 Instance RHEL 8 - DZone Cloud",
        "title_link": "https://dzone.com/articles/installing-and-configuring-confluent-platform-kafk",
        "service_name": "dzone.com"
      }
    ]
  },
  {
    "client_msg_id": "616df24d-c9c0-40bc-88f4-3ca0c67a6948",
    "type": "message",
    "text": "<https://pypi.org/project/noisereduce/>",
    "user": "U03UG4Q7V42",
    "ts": "1665244394.250289",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "KJXl",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://pypi.org/project/noisereduce/"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "5bc346a85286",
      "image_72": "https://avatars.slack-edge.com/2022-08-20/3968048875651_5bc346a852866218ec6b_72.png",
      "first_name": "Phillip",
      "real_name": "Phillip Atkins",
      "display_name": "Phillip Atkins",
      "team": "T03U4J8HMUG",
      "name": "Phillip",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://pypi.org/project/noisereduce/",
        "image_url": "https://pypi.org/static/images/twitter.6fecba6f.jpg",
        "image_width": 250,
        "image_height": 250,
        "image_bytes": 6869,
        "service_icon": "https://pypi.org/static/images/favicon.6a76275d.ico",
        "id": 1,
        "original_url": "https://pypi.org/project/noisereduce/",
        "fallback": "PyPI: noisereduce",
        "text": "Noise reduction using Spectral Gating in python",
        "title": "noisereduce",
        "title_link": "https://pypi.org/project/noisereduce/",
        "service_name": "PyPI"
      }
    ]
  },
  {
    "client_msg_id": "b1783925-69c6-44ab-bc34-8afd9789da0f",
    "type": "message",
    "text": "<https://medium.com/jakartasmartcity/data-pipeline-using-apache-airflow-to-import-data-from-public-api-7ff719118ac8>",
    "user": "U03UJN29Y4C",
    "ts": "1665244953.322419",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "GpQu",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://medium.com/jakartasmartcity/data-pipeline-using-apache-airflow-to-import-data-from-public-api-7ff719118ac8"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "9bf024280cf1",
      "image_72": "https://avatars.slack-edge.com/2022-10-08/4190947116101_9bf024280cf14dffb003_72.jpg",
      "first_name": "Michelle",
      "real_name": "Michelle Lewis",
      "display_name": "Michelle Lewis",
      "team": "T03U4J8HMUG",
      "name": "Michelle",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://medium.com/jakartasmartcity/data-pipeline-using-apache-airflow-to-import-data-from-public-api-7ff719118ac8",
        "ts": 1634199980,
        "image_url": "https://miro.medium.com/max/1200/1*ulg-zhDnYQ4Zcw-dJnUynA.jpeg",
        "image_width": 444,
        "image_height": 250,
        "image_bytes": 120336,
        "service_icon": "https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png",
        "id": 1,
        "original_url": "https://medium.com/jakartasmartcity/data-pipeline-using-apache-airflow-to-import-data-from-public-api-7ff719118ac8",
        "fallback": "Medium: Data Pipeline using Apache Airflow to Import Data from Public API",
        "text": "A tutorial to write a data pipeline that imports time-series data from a public API and inserts it into the local database scheduled daily.",
        "title": "Data Pipeline using Apache Airflow to Import Data from Public API",
        "title_link": "https://medium.com/jakartasmartcity/data-pipeline-using-apache-airflow-to-import-data-from-public-api-7ff719118ac8",
        "service_name": "Medium",
        "fields": [
          {
            "value": "8 min read",
            "title": "Reading time",
            "short": true
          }
        ]
      }
    ]
  },
  {
    "client_msg_id": "1154a926-732c-483a-8fd2-89e0caeadfe2",
    "type": "message",
    "text": "<https://pybit.es/articles/pytest-tips/>",
    "user": "U03UJN29Y4C",
    "ts": "1665245039.480399",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "KDNP",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://pybit.es/articles/pytest-tips/"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "9bf024280cf1",
      "image_72": "https://avatars.slack-edge.com/2022-10-08/4190947116101_9bf024280cf14dffb003_72.jpg",
      "first_name": "Michelle",
      "real_name": "Michelle Lewis",
      "display_name": "Michelle Lewis",
      "team": "T03U4J8HMUG",
      "name": "Michelle",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://pybit.es/articles/pytest-tips/",
        "ts": 1614351300,
        "image_url": "https://i0.wp.com/pybit.es/wp-content/uploads/2022/04/pybites-social-og-image.png",
        "image_width": 476,
        "image_height": 250,
        "image_bytes": 21612,
        "service_icon": "https://i0.wp.com/pybit.es/wp-content/uploads/2022/03/cropped-pybites-icon-favicon-rgb-colour.png?fit=180%2C180&amp;ssl=1",
        "id": 1,
        "original_url": "https://pybit.es/articles/pytest-tips/",
        "fallback": "PyBites: 10 Cool Pytest Tips You Might Not Know About - PyBites",
        "text": "Here are 10 things we learned writing pytest code that might come in handy.",
        "title": "10 Cool Pytest Tips You Might Not Know About - PyBites",
        "title_link": "https://pybit.es/articles/pytest-tips/",
        "service_name": "PyBites",
        "fields": [
          {
            "value": "Bob Belderbos",
            "title": "Written by",
            "short": true
          },
          {
            "value": "6 minutes",
            "title": "Time to read",
            "short": true
          }
        ]
      }
    ]
  },
  {
    "client_msg_id": "20a29003-c459-4c6c-8fbc-3a05e8af0ceb",
    "type": "message",
    "text": "<https://amalgjose.com/2020/08/10/program-to-stream-large-data-from-a-rest-endpoint-using-python/>",
    "user": "U03UJN29Y4C",
    "ts": "1665245058.396939",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "8TfB",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://amalgjose.com/2020/08/10/program-to-stream-large-data-from-a-rest-endpoint-using-python/"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "9bf024280cf1",
      "image_72": "https://avatars.slack-edge.com/2022-10-08/4190947116101_9bf024280cf14dffb003_72.jpg",
      "first_name": "Michelle",
      "real_name": "Michelle Lewis",
      "display_name": "Michelle Lewis",
      "team": "T03U4J8HMUG",
      "name": "Michelle",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://amalgjose.com/2020/08/10/program-to-stream-large-data-from-a-rest-endpoint-using-python/",
        "service_icon": "https://amalgjose.files.wordpress.com/2020/08/cropped-android-chrome-512x512-1.png?w=180",
        "id": 1,
        "original_url": "https://amalgjose.com/2020/08/10/program-to-stream-large-data-from-a-rest-endpoint-using-python/",
        "fallback": "All About Tech Link: Program to Stream large data from a REST endpoint using&nbsp;Python",
        "text": "Sometimes we get use cases where we have to deal with large response from a REST endpoint. For example I have a REST endpoint that gives response with size ranges in several GBs. In this case if we use the normal way to request/response, the program will consume so much memory and may even break because of memory issues.\nThe best approach to handle these kind of scenarios is by streaming the response. In this way the program will not hold the entire response in memory. Instead it will stream the data and send it to the target. In our case the target is a file.\nThe sample program is given below. This program demonstrates a POST method. But we can do the same with GET method also. The chunk size can be adjusted based on your convenience. This will be very useful in case if you have a execute program in a small sized machine that deals with responses of large size.\n.gist table { margin-bottom: 0; }\n\n\n\n\n\n\n  \n\n      \n      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.Learn more about bidirectional Unicode characters\n            Show hidden characters\n\n\n\n\nimport requests\n\n\n\n\nsession = requests.Session()\n\nauthentication = {\"USER\":\"\", \"PASSWORD\":\"\"}\n\npayload = {\"query\":\"some query\"}\n\nlocal_file = \"data.json\"\n\n\n\n\n# This is a dummy URL. You can replace this with the actual URL\n\nURL = \"\n\n\n\n\n# This is a POST request\n\nwith (URL, stream=True, data=payload, auth=(authentication[\"USER\"], authentication[\"PASSWORD\"]), verify=False) as r:\n\n    r.raise_for_status()\n\n    with open(local_file, 'wb') as f:\n\n        for chunk in r.iter_content(chunk_size=128):\n\n            f.write(chunk)\n\n\n\n\n        view raw\n          stream_data.py\n        hosted with &#10084; by GitHub",
        "title": "Program to Stream large data from a REST endpoint using\u00a0Python",
        "title_link": "https://amalgjose.com/2020/08/10/program-to-stream-large-data-from-a-rest-endpoint-using-python/",
        "author_name": "Amal G Jose",
        "author_link": "https://amalgjose.com/author/amalgjose/",
        "service_name": "All About Tech",
        "service_url": "http://amalgjose.com/"
      }
    ]
  },
  {
    "client_msg_id": "dbe82845-376d-4212-a398-e35697175cd9",
    "type": "message",
    "text": "<https://blog.logrocket.com/apache-kafka-real-time-data-streaming-app/>",
    "user": "U03V6HMRPGQ",
    "ts": "1665250593.170519",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "+6Mhl",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://blog.logrocket.com/apache-kafka-real-time-data-streaming-app/"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "23fcf5329c03",
      "image_72": "https://avatars.slack-edge.com/2022-08-22/3969139924917_23fcf5329c03131c761f_72.png",
      "first_name": "Cristian",
      "real_name": "Cristian Wilson",
      "display_name": "Cristian Wilson",
      "team": "T03U4J8HMUG",
      "name": "Cristian",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://blog.logrocket.com/apache-kafka-real-time-data-streaming-app/",
        "ts": 1646335832,
        "image_url": "https://blog.logrocket.com/wp-content/uploads/2019/11/apache-kafka-real-time-data-stream-app-nocdn.png",
        "image_width": 375,
        "image_height": 250,
        "image_bytes": 317182,
        "service_icon": "https://blog.logrocket.com/wp-content/uploads/2019/06/cropped-cropped-favicon-196x196-180x180.png",
        "id": 1,
        "original_url": "https://blog.logrocket.com/apache-kafka-real-time-data-streaming-app/",
        "fallback": "LogRocket Blog: Apache Kafka: real-time data streaming app | LogRocket Blog",
        "text": "Review key concepts for Apache Kafka. Learn how to use Apache Kafka to build a minimal real-time data streaming application.",
        "title": "Apache Kafka: real-time data streaming app | LogRocket Blog",
        "title_link": "https://blog.logrocket.com/apache-kafka-real-time-data-streaming-app/",
        "service_name": "LogRocket Blog",
        "fields": [
          {
            "value": "Alexander Nnakwue",
            "title": "Written by",
            "short": true
          },
          {
            "value": "16 minutes",
            "title": "Est. reading time",
            "short": true
          }
        ]
      }
    ]
  },
  {
    "client_msg_id": "b8c648ec-a7bd-4a1b-8cda-6e3fda8df8cc",
    "type": "message",
    "text": "<https://kafka.js.org/docs/getting-started>",
    "user": "U03V6HMRPGQ",
    "ts": "1665250605.499189",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "iE2r",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://kafka.js.org/docs/getting-started"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "23fcf5329c03",
      "image_72": "https://avatars.slack-edge.com/2022-08-22/3969139924917_23fcf5329c03131c761f_72.png",
      "first_name": "Cristian",
      "real_name": "Cristian Wilson",
      "display_name": "Cristian Wilson",
      "team": "T03U4J8HMUG",
      "name": "Cristian",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://kafka.js.org/docs/getting-started",
        "service_icon": "https://kafka.js.org/img/favicon.png",
        "id": 1,
        "original_url": "https://kafka.js.org/docs/getting-started",
        "fallback": "Getting Started \u00b7 KafkaJS",
        "text": "Install KafkaJS using [`yarn`](<https://yarnpkg.com/en/package/kafkajs>):",
        "title": "Getting Started \u00b7 KafkaJS",
        "title_link": "https://kafka.js.org/docs/getting-started",
        "service_name": "kafka.js.org"
      }
    ]
  },
  {
    "client_msg_id": "b419b7c7-8757-4c99-9f9c-1b69da111a76",
    "type": "message",
    "text": "<https://www.digitalocean.com/community/tutorials/getting-started-with-react-hooks>",
    "user": "U03V6HMRPGQ",
    "ts": "1665250626.711879",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "FS1m",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.digitalocean.com/community/tutorials/getting-started-with-react-hooks"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "23fcf5329c03",
      "image_72": "https://avatars.slack-edge.com/2022-08-22/3969139924917_23fcf5329c03131c761f_72.png",
      "first_name": "Cristian",
      "real_name": "Cristian Wilson",
      "display_name": "Cristian Wilson",
      "team": "T03U4J8HMUG",
      "name": "Cristian",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.digitalocean.com/community/tutorials/getting-started-with-react-hooks",
        "thumb_url": "https://www.digitalocean.com/_next/static/media/intro-to-cloud.d49bc5f7.jpeg",
        "thumb_width": 750,
        "thumb_height": 357,
        "service_icon": "https://www.digitalocean.com/_next/static/media/apple-touch-icon.d7edaa01.png",
        "id": 1,
        "original_url": "https://www.digitalocean.com/community/tutorials/getting-started-with-react-hooks",
        "fallback": "How To Apply React Hooks in a React Project  | DigitalOcean",
        "text": "React Hooks are functions and serve as a modular replacement for state and lifecycle methods. In this article, you will explore how to use React Hooks.",
        "title": "How To Apply React Hooks in a React Project  | DigitalOcean",
        "title_link": "https://www.digitalocean.com/community/tutorials/getting-started-with-react-hooks",
        "service_name": "digitalocean.com"
      }
    ]
  },
  {
    "client_msg_id": "3b625818-4bfe-406e-add7-c903fc1f27b4",
    "type": "message",
    "text": "<https://medium.com/apache-airflow/apache-airflow-2-0-tutorial-41329bbf7211>",
    "user": "U03UG0SFHGT",
    "ts": "1665254523.801509",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "HkHs",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://medium.com/apache-airflow/apache-airflow-2-0-tutorial-41329bbf7211"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "60e1cb8a7a1b",
      "image_72": "https://avatars.slack-edge.com/2022-08-20/3953568416743_60e1cb8a7a1b6c71c2bb_72.jpg",
      "first_name": "Willie",
      "real_name": "Willie Yang",
      "display_name": "Willie Yang",
      "team": "T03U4J8HMUG",
      "name": "Willie",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://medium.com/apache-airflow/apache-airflow-2-0-tutorial-41329bbf7211",
        "ts": 1614093080,
        "image_url": "https://miro.medium.com/max/1200/1*cVmEr0we-EbGgEqf8GaLTw.png",
        "image_width": 798,
        "image_height": 250,
        "image_bytes": 123544,
        "service_icon": "https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png",
        "id": 1,
        "original_url": "https://medium.com/apache-airflow/apache-airflow-2-0-tutorial-41329bbf7211",
        "fallback": "Medium: Apache Airflow 2.0 Tutorial",
        "text": "Apache Airflow is already a commonly used tool for scheduling data pipelines. But the upcoming Airflow 2.0 is going to be a bigger thing\u2026",
        "title": "Apache Airflow 2.0 Tutorial",
        "title_link": "https://medium.com/apache-airflow/apache-airflow-2-0-tutorial-41329bbf7211",
        "service_name": "Medium",
        "fields": [
          {
            "value": "11 min read",
            "title": "Reading time",
            "short": true
          }
        ]
      }
    ]
  }
]